{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165a3407",
   "metadata": {},
   "source": [
    "## Querying a Redis index\n",
    "\n",
    "Simple example on how to query content from a PostgreSQL+pgvector VectorStore.\n",
    "\n",
    "Requirements:\n",
    "- A PostgreSQL cluster with the pgvector extension installed (https://github.com/pgvector/pgvector)\n",
    "- A Database created in the cluster with the extension enabled (in this example, the database is named `vectordb`. Run the following command in the database as a superuser:\n",
    "`CREATE EXTENSION vector;`\n",
    "- All the information to connect to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac3132-6929-4477-9585-31761d7d9848",
   "metadata": {},
   "source": [
    "### Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed97389-9c5b-46a8-bedf-f28bf7038a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pgvector pypdf psycopg langchain sentence-transformers lxml_html_clean langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8ecae",
   "metadata": {},
   "source": [
    "### Base parameters, the PostgreSQL info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9376e567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"postgresql+psycopg://vectordb:vectordb@postgresql-service.ic-shared-rag-llm.svc.cluster.local:5432/vectordb\"\n",
    "COLLECTION_NAME = \"documents_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4572e1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e11d23-c0ad-4875-b67f-149fc8b14725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from lxml.html.clean import clean_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d51868",
   "metadata": {},
   "source": [
    "### Initialize the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "store = PGVector(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856851c",
   "metadata": {},
   "source": [
    "### Make a query to the index to verify sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9621e231-3541-40bc-85ef-8aa3b2ba2331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index\n",
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index\n",
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index\n",
      "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index\n"
     ]
    }
   ],
   "source": [
    "query=\"How do you create a Data Science Project?\"\n",
    "results =store.similarity_search(query, k=4, return_metadata=True)\n",
    "for result in results:\n",
    "    print(result.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1005e2c",
   "metadata": {},
   "source": [
    "### Work with a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566f9347-a40a-4eeb-a690-e199b91947a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 4, \"score_threshold\": 0.2 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c378fbd-395d-43af-8cca-268bc05d0f51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Gathering, cleaning, and preparing data. Data often has to be federated from a range of\\nsources, and exploring and understanding data plays a key role in the success of a data science\\nproject.\\nEvaluating and selecting ML models for your business use case.\\nTrain models for your business use case by tuning model parameters based on your set of\\ntraining data. In practice, data scientists train a range of models, and compare performance\\nwhile considering tradeoffs such as time and memory constraints.\\nIntegrate models into an application, including deployment and testing. After model training, the\\nnext step of the workflow is production. Data scientists are often responsible for putting the\\nmodel in production and making it accessible so that a developer can integrate the model into\\nan application.\\nMonitor and manage deployed models. Depending on the organization, data scientists, data\\nCHAPTER 1. OVERVIEW\\n3', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index', 'page': 6}),\n",
       " Document(page_content='Gathering, cleaning, and preparing data. Data often has to be federated from a range of\\nsources, and exploring and understanding data plays a key role in the success of a data science\\nproject.\\nEvaluating and selecting ML models for your business use case.\\nTrain models for your business use case by tuning model parameters based on your set of\\ntraining data. In practice, data scientists train a range of models, and compare performance\\nwhile considering tradeoffs such as time and memory constraints.\\nIntegrate models into an application, including deployment and testing. After model training, the\\nnext step of the workflow is production. Data scientists are often responsible for putting the\\nmodel in production and making it accessible so that a developer can integrate the model into\\nan application.\\nMonitor and manage deployed models. Depending on the organization, data scientists, data\\nCHAPTER 1. OVERVIEW\\n3', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index', 'page': 6}),\n",
       " Document(page_content='Gathering, cleaning, and preparing data. Data often has to be federated from a range of\\nsources, and exploring and understanding data plays a key role in the success of a data science\\nproject.\\nEvaluating and selecting ML models for your business use case.\\nTrain models for your business use case by tuning model parameters based on your set of\\ntraining data. In practice, data scientists train a range of models, and compare performance\\nwhile considering tradeoffs such as time and memory constraints.\\nIntegrate models into an application, including deployment and testing. After model training, the\\nnext step of the workflow is production. Data scientists are often responsible for putting the\\nmodel in production and making it accessible so that a developer can integrate the model into\\nan application.\\nMonitor and manage deployed models. Depending on the organization, data scientists, data\\nCHAPTER 1. OVERVIEW\\n3', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index', 'page': 6}),\n",
       " Document(page_content='Gathering, cleaning, and preparing data. Data often has to be federated from a range of\\nsources, and exploring and understanding data plays a key role in the success of a data science\\nproject.\\nEvaluating and selecting ML models for your business use case.\\nTrain models for your business use case by tuning model parameters based on your set of\\ntraining data. In practice, data scientists train a range of models, and compare performance\\nwhile considering tradeoffs such as time and memory constraints.\\nIntegrate models into an application, including deployment and testing. After model training, the\\nnext step of the workflow is production. Data scientists are often responsible for putting the\\nmodel in production and making it accessible so that a developer can integrate the model into\\nan application.\\nMonitor and manage deployed models. Depending on the organization, data scientists, data\\nCHAPTER 1. OVERVIEW\\n3', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index', 'page': 6})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d33989-1403-48bf-99b5-0e78deda1523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
